# golang的临时对象池

## sync.Pool的使用

Golang的sync包提供了一个可被重复利用的实例池sync.Pool，其目的是为了降低垃圾回收的压力。当对象特别大或者使用非常频繁的时候可以使用以减少gc的开销。根据官方文档，它有如下一些特点：

- 不要去拷贝pool，最好使用单例

- 多线程安全 

- 自动扩容和自动缩容

- 当对象的引用只有sync.Pool持有时，这个对象会被gc回收  

sync.Pool对外暴露了三个接口：

```go
func (p *Pool) Get() interface {}

func (p *Pool) Put() (x interface{})

New func() interface{}
```
- 通过New定义这个池子里存的数据，这里只能存一种类型的数据

- 通过Get方法从池子里取出之前New里定义的类型数据

- 通过Put方法将刚刚的对象放回去

```go
package main

import (
    "fmt"
    "sync"
)

var strPool = sync.Pool{
    New: func() interface{} {
        return "test str"
    },
}

func main() {
    str := strPool.Get()
    fmt.Println(str)
    strPool.Put(str)
}
```
## sync.Pool的源码分析

下面从源码层面走流程，分析一遍sync.Pool，这里的golang版本：go1.13

数据结构

```go
type Pool struct {
    noCopy noCopy

    local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
    localSize uintptr        // size of the local array

    victim     unsafe.Pointer // local from previous cycle
    victimSize uintptr        // size of victims array

    // New optionally specifies a function to generate
    // a value when Get would otherwise return nil.
    // It may not be changed concurrently with calls to Get.
    New func() interface{}
}

// Local per-P Pool appendix.
type poolLocalInternal struct {
    private interface{} // Can be used only by the respective P.
    shared  poolChain   // Local P can pushHead/popHead; any P can popTail.
}

type poolLocal struct {
    poolLocalInternal

    // Prevents false sharing on widespread platforms with
    // 128 mod (cache line size) = 0 .
    pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte
}

```
- noCopy是为防止Pool被拷贝，Pool在Golang中是全局唯一的，Golang中没有原生禁止拷贝的方式，所以go的作者做了个约定：只要包含实现sync.Locker这个接口的结构体noCopy，go vet就可以帮助我们检查是否被拷贝了。

- local里面存储的是[P]poolLocal，其中P是GPM模型中的P，有多少个P，数组就有多大，每个P维护了一个本地的poolLocal。

- poolLocal里面维护了一个private和一个shared，private是给自己用的，而shared是一个队列，可以供别人使用，，这里的结构是一个双向链表，自己从队列的头部存然后从头部取，别的P从尾部取

- victim里保存gc时留下的对象，当进行GC的时候，会将local中的对象移到victim中去，也就是说幸存了一次GC

- pad的主要作用是防止伪共享（false sharing），缓存系统中是以缓存行为单位存储的，当缓存行加载其中1个字节的时候，其他63个也会被加载出来，加锁会锁住整个缓存行，这里会引起锁竞争，这种现象称为伪共享，解决办法是补齐缓存行，让每个数据都是独立的缓存行，以免出现false sharing

Get()方法

```go
func (p *Pool) Get() interface{} {
    ......
    l, pid := p.pin()
    x := l.private
    l.private = nil
    if x == nil {
        // Try to pop the head of the local shard. We prefer
        // the head over the tail for temporal locality of
        // reuse.
        x, _ = l.shared.popHead()
        if x == nil {
            x = p.getSlow(pid)
        }
    }
    runtime_procUnpin()
    ......
    if x == nil && p.New != nil {
        x = p.New()
    }
    return x
}

func (p *Pool) getSlow(pid int) interface{} {
    // See the comment in pin regarding ordering of the loads.
    size := atomic.LoadUintptr(&p.localSize) // load-acquire
    locals := p.local                        // load-consume
    // Try to steal one element from other procs.
    for i := 0; i < int(size); i++ {
        l := indexLocal(locals, (pid+i+1)%int(size))
        if x, _ := l.shared.popTail(); x != nil {
            return x
        }
    }

    // Try the victim cache. We do this after attempting to steal
    // from all primary caches because we want objects in the
    // victim cache to age out if at all possible.
    size = atomic.LoadUintptr(&p.victimSize)
    if uintptr(pid) >= size {
        return nil
    }
    locals = p.victim
    l := indexLocal(locals, pid)
    if x := l.private; x != nil {
        l.private = nil
        return x
    }
    for i := 0; i < int(size); i++ {
        l := indexLocal(locals, (pid+i)%int(size))
        if x, _ := l.shared.popTail(); x != nil {
            return x
        }
    }

    // Mark the victim cache as empty for future gets don't bother
    // with it.
    atomic.StoreUintptr(&p.victimSize, 0)

    return nil
}
```
- 如果private不是空的，就直接拿来用

- 如果private是空的，先去本地的shared队列里从头pop一个

- 如果本地的shared也没有，就去getSlow拿，去别的shared里steal一个，如果没有回到victim里找

- 如果最后都没有，调用New方法创建一个

pin()获取per-P的localPool

```go
// pin函数会将当前 goroutine绑定的P, 禁止抢占(preemption) 并从 poolLocal 池中返回 P 对应的 poolLocal
// Caller must call runtime_procUnpin() when done with the pool.
func (p *Pool) pin() *poolLocal {
	pid := runtime_procPin()
	// 在 pinSlow 中会存储 localSize 后再存储 local，因此这里反过来读取
	// 因为我们已经禁用了抢占，这时不会发生 GC
	// 因此，我们必须观察 local 和 localSize 是否对应
	// 观察到一个全新或很大的的 local 是正常行为
	s := atomic.LoadUintptr(&p.localSize) // load-acquire
	l := p.local                          // load-consume
	// 因为可能存在动态的 P（运行时调整 P 的个数）procresize/GOMAXPROCS
	// 如果 P.id 没有越界，则直接返回
	if uintptr(pid) < s {
		return indexLocal(l, pid)
	}
	// 没有结果时，涉及全局加锁
	// 例如重新分配数组内存，添加到全局列表
	return p.pinSlow()
}


//go:linkname sync_runtime_procPin sync.runtime_procPin
//go:nosplit
func sync_runtime_procPin() int {
	return procPin()
}


//go:nosplit
func procPin() int {
	_g_ := getg()
	mp := _g_.m

	mp.locks++
	return int(mp.p.ptr().id)
}
```
pin函数首先会调用运行时实现获得当前P的id，然后设置P禁止抢占（避免GC）。然后检查pid与p.localSize值来确保从p.local中取值不会发生越界。如果不会发生，则调用indexLocal()完成取值，否则还需要继续调用pinSlow()。

这里调用了runtime_procPin()来实现runtime的P，并设置禁止抢占，然后返回P的id

在这个过程中我们可以看到在runtime调整P的大小的代价。如果此时P被调大，而没有对应的poolLocal时，必须在取之前建好，从而必须依赖全局加锁，这对于以性能著称的池化概念是比较致命的，因此这也是pinSlow()函数的由来。

pinSlow()函数源码

因为需要对全局进行加锁，pinSlow()会首先取消P的不可抢占，然后使用allPoolsMu进行加锁

```go
var (
	allPoolsMu	Mutex
	allPools	[]*Pool
)
```
这里可以看到，Pool里面有全局变量持有了所有的Pool，然后也有一个全局锁来保护数据域的安全性

pinSlow源码：

```go
func (p *Pool) pinSlow() *poolLocal {
	// 这时取消 P 的禁止抢占，因为使用 mutex 时候 P 必须可抢占
	runtime_procUnpin()
	allPoolsMu.Lock()
	defer allPoolsMu.Unlock()
	// 当锁住后，再次固定 P 取其 id
	pid := runtime_procPin()
	// 并再次检查是否符合条件，因为可能中途已被其他线程调用
	// 当再次固定 P 时 poolCleanup 不会被调用
	s := p.localSize
	l := p.local
	if uintptr(pid) < s {
		return indexLocal(l, pid)
	}
	// 如果数组为空，新建
	// 将其添加到 allPools，垃圾回收器从这里获取所有 Pool 实例
	if p.local == nil {
		allPools = append(allPools, p)
	}
	// 根据 P 数量创建 slice，如果 GOMAXPROCS 在 GC 间发生变化
	// 我们重新分配此数组并丢弃旧的
	size := runtime.GOMAXPROCS(0)
	local := make([]poolLocal, size)
	atomic.StorePointer(&p.local, unsafe.Pointer(&local[0])) // store-release
	atomic.StoreUintptr(&p.localSize, uintptr(size))         // store-release
	return &local[pid]
}
```
- pinSlow()首先取消P的不可抢占，然后使用allPoolsMu进行加锁

- 当完成加锁后，再重新固定P，取其pid

- 因为中途可能已经被其他线程调用，因此这时候需要再次对pid进行检查，如果pid在p.local大小范围内，则不再此时创建，直接返回。

- 如果p.local为空，则将p扔给allPools并在垃圾回收阶段回收所有Pool实例。

- 最后完成对p.local的创建（彻底丢弃旧数组）

getSlow()方法 steal from other per-P localPool

现在我们获取到了poolLocal，Get操作回到了从localPool中取值的过程，在取对象的过程中，我们仍然会面对localPool中没有缓存的对象了（既不能从private取，也不能从shared取的尴尬境地，这时候就走到了getSlow()，也就是所谓的steal）

如果我们在本地P中取不到值，就从别的P那里偷一个，总会比创建一个新的要快。因此再次固定P，并取得当前的pid来从其他P中偷值，那么我们需要先获取到其他P对应的 poolLocal。假设size为数组的大小，local为p.local，那么尝试遍历其他所有P

```go 
func (p *Pool) getSlow() (x interface{}) {
	// See the comment in pin regarding ordering of the loads.
	size := atomic.LoadUintptr(&p.localSize) // load-acquire
	local := p.local                         // load-consume
	// Try to steal one element from other procs.
	pid := runtime_procPin()
	runtime_procUnpin()
	for i := 0; i < int(size); i++ {
		// 获取目标 poolLocal, 引入 pid 保证不是自身
		l := indexLocal(local, (pid+i+1)%int(size))
		l.Lock()
		last := len(l.shared) - 1
		if last >= 0 {
			x = l.shared[last]
			l.shared = l.shared[:last]
			l.Unlock()
			break
		}
		l.Unlock()
	}
	return x
}

```
这里证明一下确实不会发生取到自身的情况：

不妨设：pid = (pid + i + 1) % size 则 pid + i + 1 = a * size + pid 。

即：a * size = i + 1 ，其中a为整数。由于 i < size ，于是 a * size = i + 1 < size  + 1，

则：(a - 1) * size < 1 ==> size < 1 / (a - 1)，由于 size 为非负整数，这是不可能的。

Put()方法

```go
// Put adds x to the pool.
func (p *Pool) Put(x interface{}) {
    if x == nil {
        return
    }
    ......
    l, _ := p.pin()
    if l.private == nil {
        l.private = x
        x = nil
    }
    if x != nil {
        l.shared.pushHead(x)
    }
    runtime_procUnpin()
    ......
}
```
- 如果private没有，就放在private

- 如果private有了，就放在shared队列的头部

## Runtime垃圾回收Hook

sync.Pool的垃圾回收发生在运行时GC开始之前，从链路的追踪可以看到，在开始GC的时候会调用Pool的回收，也就是Pool中临时对象的生命周期是两次GC的间隔时间。

```go
func init() {
	runtime_registerPoolCleanup(poolCleanup)
}

func runtime_registerPoolCleanup(cleanup func())

//go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup
func sync_runtime_registerPoolCleanup(f func()) {
	poolcleanup = f
}

func clearpools() {
	// clear sync.Pools
	if poolcleanup != nil {
		poolcleanup()
	}
	......
}

func gcStart(trigger gcTrigger){
	.......
	clearpools()
	.......
}

```
在Pool的清理函数poolCleanup()中，将所有的对象置为nil，等待GC自动回收

```go
func poolCleanup() {
	// 该函数会注册到运行时 GC 阶段(前)，此时为 STW 状态，不需要加锁
	// 它必须不处理分配且不调用任何运行时函数，防御性的将一切归零，有以下两点原因:
	// 1. 防止整个 Pool 的 false retention
	// 2. 如果 GC 发生在当有 goroutine 与 l.shared 进行 Put/Get 时，它会保留整个 Pool.
	//   那么下个 GC 周期的内存消耗将会翻倍。
	// 遍历所有 Pool 实例，接触相关引用，交由 GC 进行回收
	for i, p := range allPools {
		allPools[i] = nil
		for i := 0; i < int(p.localSize); i++ {
			l := indexLocal(p.local, i)
			l.private = nil
			for j := range l.shared {
				l.shared[j] = nil
			}
			l.shared = nil
		}
		p.local = nil
		p.localSize = 0
	}
	allPools = []*Pool{}
}
```

整个设计充分利用了go.runtime的调度器优势：一个P下goroutine竞争的无锁化；

一个goroutine固定在一个局部调度器P上，从当前 P 对应的 poolLocal 取值， 若取不到，则从对应的 shared 数组上取，若还是取不到；则尝试从其他 P 的 shared 中偷。 若偷不到，则调用 New 创建一个新的对象。池中所有临时对象在一次 GC 后会被全部清空。























